{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5fd2918-134c-4343-aaa1-ef1735ca5123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PIPELINE PENGUINS - Preparación de datos\n",
      "============================================================\n",
      "\n",
      "--- 1. CARGA ---\n",
      "Filas: 344, Columnas: ['species', 'island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex', 'year']\n",
      "\n",
      "--- 2. LIMPIEZA ---\n",
      "Filas eliminadas por faltantes: 11. Restantes: 333\n",
      "\n",
      "--- 3. TRANSFORMACIÓN ---\n",
      "Tipos numéricos aplicados. Filas: 333\n",
      "\n",
      "--- 4. VALIDACIÓN ---\n",
      "Validación OK: sin nulos en target, múltiples clases, datos suficientes.\n",
      "\n",
      "--- 5. INGENIERÍA DE CARACTERÍSTICAS ---\n",
      "Features: ['island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex', 'year']. Target: species. Clases: ['Adelie', 'Gentoo', 'Chinstrap']\n",
      "\n",
      "--- 6. DIVISIÓN ---\n",
      "Train: 266, Test: 67\n",
      "\n",
      "============================================================\n",
      "PIPELINE PENGUINS - Creación de modelos\n",
      "============================================================\n",
      "\n",
      "--- CONSTRUCCIÓN (RF) ---\n",
      "\n",
      "--- ENTRENAMIENTO (RF) ---\n",
      "Entrenamiento completado.\n",
      "\n",
      "--- VALIDACIÓN DEL MODELO (RF) ---\n",
      "Accuracy: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       1.00      1.00      1.00        29\n",
      "   Chinstrap       1.00      1.00      1.00        14\n",
      "      Gentoo       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           1.00        67\n",
      "   macro avg       1.00      1.00      1.00        67\n",
      "weighted avg       1.00      1.00      1.00        67\n",
      "\n",
      "Confusion matrix:\n",
      " [[29  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0 24]]\n",
      "Modelo guardado: /workspace/commons/Model/RF.pkl\n",
      "\n",
      "--- CONSTRUCCIÓN (LR) ---\n",
      "\n",
      "--- ENTRENAMIENTO (LR) ---\n",
      "Entrenamiento completado.\n",
      "\n",
      "--- VALIDACIÓN DEL MODELO (LR) ---\n",
      "Accuracy: 0.9851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       1.00      0.97      0.98        29\n",
      "   Chinstrap       0.93      1.00      0.97        14\n",
      "      Gentoo       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           0.99        67\n",
      "   macro avg       0.98      0.99      0.98        67\n",
      "weighted avg       0.99      0.99      0.99        67\n",
      "\n",
      "Confusion matrix:\n",
      " [[28  1  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0 24]]\n",
      "Modelo guardado: /workspace/commons/Model/LR.pkl\n",
      "\n",
      "============================================================\n",
      "RF.pkl y LR.pkl generados en el directorio Model.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pipeline de entrenamiento para clasificación de especies de pingüinos.\n",
    "Usa Random Forest (RF) y Logistic Regression (LR) para predecir 'species'.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Ruta al dataset (desde la raíz del proyecto)\n",
    "#PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "#DATASET_PATH = os.path.join(PROJECT_ROOT, \"Dataset\", \"penguins.csv\")\n",
    "#MODEL_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "#PROJECT_ROOT = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "PROJECT_ROOT = (os.path.dirname(os.getcwd()))\n",
    "#print (PROJECT_ROOT)\n",
    "DATASET_PATH = os.path.join(PROJECT_ROOT, \"Dataset\", \"penguins.csv\")\n",
    "MODEL_DIR = os.getcwd()\n",
    "\n",
    "\n",
    "\n",
    "# ============== 1. PREPARACIÓN DE DATOS ==============\n",
    "\n",
    "def step_load():\n",
    "    \"\"\"1. Carga: leer el CSV del dataset.\"\"\"\n",
    "    print(\"\\n--- 1. CARGA ---\")\n",
    "    df = pd.read_csv(DATASET_PATH)\n",
    "    print(f\"Filas: {len(df)}, Columnas: {list(df.columns)}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def step_clean(df):\n",
    "    \"\"\"2. Limpieza: manejar NA y valores inconsistentes.\"\"\"\n",
    "    print(\"\\n--- 2. LIMPIEZA ---\")\n",
    "    # Reemplazar 'NA' string por np.nan si existe\n",
    "    df = df.replace(\"NA\", np.nan)\n",
    "    # Eliminar filas con valores faltantes\n",
    "    before = len(df)\n",
    "    df = df.dropna()\n",
    "    print(f\"Filas eliminadas por faltantes: {before - len(df)}. Restantes: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def step_transform(df):\n",
    "    \"\"\"3. Transformación: tipos y formatos adecuados.\"\"\"\n",
    "    print(\"\\n--- 3. TRANSFORMACIÓN ---\")\n",
    "    numeric_cols = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\", \"year\"]\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df = df.dropna()\n",
    "    print(f\"Tipos numéricos aplicados. Filas: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def step_validate(df):\n",
    "    \"\"\"4. Validación: comprobar integridad y rangos.\"\"\"\n",
    "    print(\"\\n--- 4. VALIDACIÓN ---\")\n",
    "    assert df[\"species\"].notna().all(), \"species tiene nulos\"\n",
    "    assert df[\"species\"].nunique() >= 2, \"Se necesitan al menos 2 clases en species\"\n",
    "    assert len(df) > 0, \"DataFrame vacío tras limpieza\"\n",
    "    print(\"Validación OK: sin nulos en target, múltiples clases, datos suficientes.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def step_feature_engineering(df):\n",
    "    \"\"\"5. Ingeniería de características: preparar X e y.\"\"\"\n",
    "    print(\"\\n--- 5. INGENIERÍA DE CARACTERÍSTICAS ---\")\n",
    "    target = \"species\"\n",
    "    feature_cols = [c for c in df.columns if c != target]\n",
    "    X = df[feature_cols]\n",
    "    y = df[target]\n",
    "    print(f\"Features: {list(X.columns)}. Target: {target}. Clases: {list(y.unique())}\")\n",
    "    return X, y, feature_cols\n",
    "\n",
    "\n",
    "def step_split(X, y, feature_cols):\n",
    "    \"\"\"6. División: train/test con estratificación por species.\"\"\"\n",
    "    print(\"\\n--- 6. DIVISIÓN ---\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "    return X_train, X_test, y_train, y_test, feature_cols\n",
    "\n",
    "\n",
    "# ============== 2. CREACIÓN DE MODELOS ==============\n",
    "\n",
    "def get_preprocessor(feature_cols):\n",
    "    \"\"\"Preprocesador: numéricos (escalado) + categóricos (one-hot).\"\"\"\n",
    "    numeric_features = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\", \"year\"]\n",
    "    numeric_features = [f for f in numeric_features if f in feature_cols]\n",
    "    categorical_features = [f for f in feature_cols if f not in numeric_features]\n",
    "    transformers = []\n",
    "    if numeric_features:\n",
    "        transformers.append((\"num\", StandardScaler(), numeric_features))\n",
    "    if categorical_features:\n",
    "        transformers.append(\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features)\n",
    "        )\n",
    "    return ColumnTransformer(transformers, remainder=\"passthrough\")\n",
    "\n",
    "\n",
    "def step_build(model_name=\"RF\"):\n",
    "    \"\"\"Construcción: definir pipeline del modelo.\"\"\"\n",
    "    print(f\"\\n--- CONSTRUCCIÓN ({model_name}) ---\")\n",
    "    # feature_cols se define después del split; aquí solo creamos el estimador base\n",
    "    if model_name == \"RF\":\n",
    "        estimator = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    else:\n",
    "        estimator = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    return estimator\n",
    "\n",
    "\n",
    "def step_train(estimator, preprocessor, X_train, y_train, model_name):\n",
    "    \"\"\"Entrenamiento: ajustar pipeline completo.\"\"\"\n",
    "    print(f\"\\n--- ENTRENAMIENTO ({model_name}) ---\")\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", estimator),\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print(\"Entrenamiento completado.\")\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def step_validate_model(pipeline, X_test, y_test, model_name):\n",
    "    \"\"\"Validación del modelo: métricas en test.\"\"\"\n",
    "    print(f\"\\n--- VALIDACIÓN DEL MODELO ({model_name}) ---\")\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    return acc\n",
    "\n",
    "\n",
    "def save_model_as_pkl(pipeline, filename):\n",
    "    \"\"\"Guarda el pipeline serializado con extensión .pkl (pickle/joblib).\"\"\"\n",
    "    path = os.path.join(MODEL_DIR, filename)\n",
    "    joblib.dump(pipeline, path)\n",
    "    print(f\"Modelo guardado: {path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PIPELINE PENGUINS - Preparación de datos\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # --- 1. Preparación de datos (6 pasos) ---\n",
    "    df = step_load()\n",
    "    df = step_clean(df)\n",
    "    df = step_transform(df)\n",
    "    df = step_validate(df)\n",
    "    X, y, feature_cols = step_feature_engineering(df)\n",
    "    X_train, X_test, y_train, y_test, feature_cols = step_split(X, y, feature_cols)\n",
    "\n",
    "    preprocessor = get_preprocessor(feature_cols)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PIPELINE PENGUINS - Creación de modelos\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for model_name in [\"RF\", \"LR\"]:\n",
    "        estimator = step_build(model_name)\n",
    "        pipeline = step_train(estimator, preprocessor, X_train, y_train, model_name)\n",
    "        step_validate_model(pipeline, X_test, y_test, model_name)\n",
    "        save_model_as_pkl(pipeline, f\"{model_name}.pkl\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RF.pkl y LR.pkl generados en el directorio Model.\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c84375e-ad61-4660-bf81-8d2d489b86dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc9197-ae50-49d8-9672-e3b90002c277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
